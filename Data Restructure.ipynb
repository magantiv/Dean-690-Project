{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# procedure table\n",
    "proce = pd.read_excel('IndividualTables.xlsx', index_col=None, sheet_name='procedures')\n",
    "proce = proce.drop(columns = ['ProcedurePrimaryKey'])\n",
    "p = pd.get_dummies(proce['ProcedurePerformed'], prefix='procedure')\n",
    "procecols = list(p.columns)\n",
    "u = list(p.columns)\n",
    "u.append('isALS_LOC')\n",
    "proce_df = pd.concat([proce.drop(columns = ['ProcedurePerformed']), p], axis = 1)\n",
    "proce_df = proce_df.groupby(['PatientID'])[u].apply(lambda x : x.sum()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# medical table\n",
    "med = pd.read_excel('IndividualTables.xlsx', index_col=None, sheet_name='medications').dropna()\n",
    "med = med.drop(columns = ['MedicationPrimaryKey'])\n",
    "m = pd.get_dummies(med['MedicationGiven'], prefix='medication')\n",
    "medcols = list(m.columns)\n",
    "u = list(m.columns)\n",
    "u.append('isALS_LOC')\n",
    "med_df = pd.concat([med.drop(columns = ['MedicationGiven']), m], axis = 1)\n",
    "med_df = med_df.groupby(['PatientID'])[u].apply(lambda x : x.sum()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patient table\n",
    "pati = pd.read_excel('IndividualTables.xlsx', index_col=None, sheet_name='patients')\n",
    "pati = pati.drop(columns = ['TransportHospitalCode', 'PatientDisposition'])\n",
    "pati = pati[~pati.PatientID.isin([918485, 997953, 918485])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reason, impression, age, hosp, transloc\n",
    "reason = pati['ReasonForChoosingHospital']\n",
    "imp = pati[['PrimaryImpression', 'SecondaryImpression']]\n",
    "age = pati['PatientAge']\n",
    "hosp = pati['TransportHospitalName']\n",
    "transloc =pati['TransportLOC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impression\n",
    "imp1 = pd.get_dummies(imp['PrimaryImpression'], prefix='impression')\n",
    "imp2 = pd.DataFrame(imp['SecondaryImpression'])\n",
    "def clean_comma(col):\n",
    "    return col.str.replace(' (ETOH)', '',regex = False).str.replace('Sedative, Hypnotic', 'Sedative Hypnotic', regex = False).str.replace(', With', 'With',regex = False).str.replace(', unspecified','unspecified',regex = False).str.replace(', suspected','suspected',regex = False).str.replace('Wrist, Hand,','Wrist Hand',regex = False).str.replace('Chemicals, Gases, Fumes,','Chemicals Gases Fumes',regex = False)\n",
    "imp2['SecondaryImpression'] = imp['SecondaryImpression'].astype(str).str.replace('\"', \"\").str.strip()\n",
    "imp2 = clean_comma(imp2['SecondaryImpression'].astype(str))\n",
    "z = imp2.str.split(',', expand=True)\n",
    "r = pd.get_dummies(z, prefix='impression')\n",
    "r.columns = r.columns.str.replace('_ ', '_', regex = False)\n",
    "cols = set(r.columns)\n",
    "result = pd.DataFrame()\n",
    "for col in cols:\n",
    "    try:\n",
    "        r[col].sum(axis = 1)\n",
    "        result[col] = r[col].sum(axis = 1)\n",
    "    except:\n",
    "        result[col] = r[col]\n",
    "imp = pd.concat([imp1, result], axis = 1)\n",
    "impcols = list(set(imp.columns))\n",
    "imp_df = pd.DataFrame()\n",
    "for col in impcols:\n",
    "    try:\n",
    "        imp[col].sum(axis = 1)\n",
    "        imp_df[col] = imp[col].sum(axis = 1)\n",
    "    except:\n",
    "        imp_df[col] = imp[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reason\n",
    "reason = pati['ReasonForChoosingHospital'].fillna('No Hospital')\n",
    "def clean_reason(col):\n",
    "    return col.str.replace('Trauma, STEMI, Stroke', 'Trauma STEMI Stroke', regex = False)\n",
    "reason = clean_reason(reason)\n",
    "reason = reason.str.split(',', expand=True)\n",
    "reason = pd.get_dummies(reason,prefix='reason')\n",
    "result = pd.DataFrame()\n",
    "cols = list(set(reason.columns))\n",
    "for col in cols:\n",
    "    try:\n",
    "        reason[col].sum(axis = 1)\n",
    "        result[col] = reason[col].sum(axis = 1)\n",
    "    except:\n",
    "        result[col] = reason[col]\n",
    "reason_df = pd.DataFrame(result)\n",
    "reasoncols = list(reason_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patient age\n",
    "age = pati['PatientAge']\n",
    "age_df = pd.get_dummies(age, prefix='patient_age')\n",
    "agecols = list(age_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TransportLOC\n",
    "transloc = pati['TransportLOC'].fillna('No Transport LOC')\n",
    "transloc_df = pd.get_dummies(transloc, prefix='transloc')\n",
    "transloccols = list(transloc_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TransportHospitalName\n",
    "hosp = pati['TransportHospitalName'].fillna('No Hospital')\n",
    "hosp_df = pd.get_dummies(hosp, prefix='hospital_name')\n",
    "hospcols = list(hosp_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine\n",
    "pati_base = pati[['PrimaryKey', 'PatientID']]\n",
    "new_pati = pd.concat([pati_base, transloc_df, hosp_df, reason_df, age_df, imp_df], axis = 1)\n",
    "full_pati = new_pati.merge(proce_df, on = 'PatientID',how = 'left').fillna(0)\n",
    "full_pati = full_pati.merge(med_df, on = 'PatientID',how = 'left').fillna(0)\n",
    "full_pati['isALS_LOC'] = full_pati['isALS_LOC_x'] + full_pati['isALS_LOC_y']\n",
    "full_pati = full_pati.drop(columns = ['isALS_LOC_x', 'isALS_LOC_y'])\n",
    "fianl_pati = full_pati.groupby('PrimaryKey')[list(full_pati.columns[2:])].apply(lambda x : x.sum()).reset_index()\n",
    "#fianl_pati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit table\n",
    "unit = pd.read_excel('IndividualTables.xlsx', index_col=None, sheet_name='units').dropna(subset = ['UnitStation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# action\n",
    "def clean_comma_act(col):\n",
    "    return col.str.replace(', ', ' ')\n",
    "act1 = clean_comma_act(unit['UnitPrimaryActionTaken']).fillna('No Action')\n",
    "act2 = clean_comma_act(unit['UnitOtherActionsTaken']).fillna('missing')\n",
    "a1 = act1.str.split(',', expand=True)\n",
    "a1 = pd.get_dummies(a1, prefix='unit_action')\n",
    "a2 = act2.str.split(',', expand=True)\n",
    "a2 = pd.get_dummies(a2, prefix='unit_action')\n",
    "cols = set(a2.columns)\n",
    "result = pd.DataFrame()\n",
    "for col in cols:\n",
    "    try:\n",
    "        a2[col].sum(axis = 1)\n",
    "        result[col] = a2[col].sum(axis = 1)\n",
    "    except:\n",
    "        result[col] = a2[col]\n",
    "a = pd.concat([a1, result], axis = 1)\n",
    "actcols = list(set(a.columns))\n",
    "act_df = pd.DataFrame()\n",
    "for col in actcols:\n",
    "    try:\n",
    "        a[col].sum(axis = 1)\n",
    "        act_df[col] = a[col].sum(axis = 1)\n",
    "    except:\n",
    "        act_df[col] = a[col]\n",
    "act_df = act_df.drop(columns = 'unit_action_missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type\n",
    "unittype = unit['UnitType']\n",
    "unittype_df = pd.get_dummies(unittype, prefix='unit_type')\n",
    "unittypecols = list(unittype_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit station\n",
    "unitsta = unit['UnitStation']\n",
    "unitsta = unitsta[~unitsta.isin([3, 33, 'PRV', 'TA'])]\n",
    "unitsta_df = pd.get_dummies(unitsta, prefix='unit_station')\n",
    "unitstacols = list(unitsta_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_base = unit[['PrimaryKey']]\n",
    "new_unit = pd.concat([unit_base, act_df, unitsta_df, unittype_df],axis = 1)\n",
    "final_unit = new_unit.groupby('PrimaryKey')[list(new_unit.columns[1:])].apply(lambda x : x.sum()).reset_index()\n",
    "#final_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "inci = pd.read_excel('IndividualTables.xlsx', index_col=None, sheet_name='incidents')\n",
    "inci = inci.drop(columns = ['ShiftDay', 'TourOfShift', 'FinalIncidentTypeDescription'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "inci['IncidentFirstDue'] = inci['IncidentFirstDue'].fillna('Outside Fairfax')\n",
    "def clean_ini(row):\n",
    "    if row['InitialIncidentType'] == 'MEDICAL':\n",
    "        return 'BLS'\n",
    "    else:\n",
    "        return row['InitialIncidentType']\n",
    "def clean_dis(row):\n",
    "    if row['DispatchedIncidentType'] == 'MEDICAL':\n",
    "        return 'BLS'\n",
    "    else:\n",
    "        return row['DispatchedIncidentType']\n",
    "def clean_arri(row):\n",
    "    if row['ArrivedIncidentType'] == 'MEDICAL':\n",
    "        return 'BLS'\n",
    "    else:\n",
    "        return row['ArrivedIncidentType']\n",
    "def clean_fina(row):\n",
    "    if row['FinalIncidentType'] == 'MEDICAL':\n",
    "        return 'BLS'\n",
    "    else:\n",
    "        return row['FinalIncidentType']\n",
    "inci['InitialIncidentType'] = inci.apply(lambda row: clean_ini(row), axis = 1)\n",
    "inci['DispatchedIncidentType'] = inci.apply(lambda row: clean_dis(row), axis = 1)\n",
    "inci['ArrivedIncidentType'] = inci.apply(lambda row: clean_arri(row), axis = 1)\n",
    "inci['FinalIncidentType'] = inci.apply(lambda row: clean_fina(row), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inci['CallDTMonth'] = inci['CallConfirmedDT'].dt.month\n",
    "inci['CallDTHour'] = inci['CallConfirmedDT'].dt.hour\n",
    "inci['CallDTDayofWeek'] = inci['CallConfirmedDT'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial\n",
    "ini = inci['InitialIncidentType']\n",
    "i = pd.get_dummies(ini, prefix='InitialIncidentType')\n",
    "# dis\n",
    "dis = inci['DispatchedIncidentType']\n",
    "d = pd.get_dummies(dis, prefix='DispatchedIncidentType')\n",
    "# arri\n",
    "arri = inci['ArrivedIncidentType']\n",
    "a = pd.get_dummies(arri, prefix='ArrivedIncidentType')\n",
    "# final\n",
    "fina = inci['FinalIncidentType']\n",
    "f = pd.get_dummies(fina, prefix='FinalIncidentType')\n",
    "# fdue\n",
    "fdue = inci['IncidentFirstDue'].apply(str)\n",
    "fdue = pd.get_dummies(fdue, prefix='IncidentFirstDue')\n",
    "inci = pd.concat([inci, fdue, i, d, a, f],axis = 1)\n",
    "inci = inci.drop(columns = ['IncidentFirstDue', 'InitialIncidentType', 'DispatchedIncidentType', 'ArrivedIncidentType', 'FinalIncidentType', 'CallConfirmedDT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = inci.merge(final_unit, on = 'PrimaryKey', how='inner')\n",
    "final_df = final_df.merge(fianl_pati, on = 'PrimaryKey', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.drop_duplicates(subset = 'PrimaryKey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_alsloc(row):\n",
    "    if row['isALS_LOC'] >= 1.0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "final_df['isALS_LOC'] = final_df.apply(lambda row: clean_alsloc(row), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write CSV\n",
    "#final_df.to_csv('MasterData_Restructured4.txt', sep = '|')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
